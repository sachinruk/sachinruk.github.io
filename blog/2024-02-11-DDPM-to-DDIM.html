<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-02-11">

<title>From DDPM to DDIM: A Mathematcal Deep Dive – deepschool.ai</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/favicon_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37284264-2', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="From DDPM to DDIM: A Mathematcal Deep Dive – deepschool.ai">
<meta property="og:description" content="">
<meta property="og:image" content="https://sachinruk.github.io/images/DDIM.png">
<meta property="og:site_name" content="deepschool.ai">
<meta property="og:image:height" content="945">
<meta property="og:image:width" content="1890">
<meta name="twitter:title" content="From DDPM to DDIM: A Mathematcal Deep Dive – deepschool.ai">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://sachinruk.github.io/images/DDIM.png">
<meta name="twitter:image-height" content="945">
<meta name="twitter:image-width" content="1890">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">deepschool.ai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../programming_tips.html"> 
<span class="menu-text">Programming Tips</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../ML_consulting.html"> 
<span class="menu-text">ML Consulting</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../DL_Course.html"> 
<span class="menu-text">DL Course</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-forward-noising-process" id="toc-the-forward-noising-process" class="nav-link" data-scroll-target="#the-forward-noising-process">The <del>forward</del> noising process</a>
  <ul class="collapse">
  <li><a href="#proof-of-q_sigmax_tx_0" id="toc-proof-of-q_sigmax_tx_0" class="nav-link" data-scroll-target="#proof-of-q_sigmax_tx_0">Proof of <span class="math inline">\(q_\sigma(x_t|x_0)\)</span></a></li>
  </ul></li>
  <li><a href="#reverse-generation-process" id="toc-reverse-generation-process" class="nav-link" data-scroll-target="#reverse-generation-process">Reverse (generation) process</a></li>
  <li><a href="#lower-bound" id="toc-lower-bound" class="nav-link" data-scroll-target="#lower-bound">Lower Bound</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  <li><a href="#accelerated-sampling" id="toc-accelerated-sampling" class="nav-link" data-scroll-target="#accelerated-sampling">Accelerated Sampling</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">From DDPM to DDIM: A Mathematcal Deep Dive</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Diffusion Models</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 11, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="../images/DDIM.png" class="img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this blog we will explore the DDIM paper with excruciating mathematical detail. In doing so, hopefully, bridge the gap between the two papers. While knowledge of DDPM is nice to have, it won’t be necessary. I will however, make frequent references to their approach.</p>
<p>Some minor points before we get into the crux of this blog:</p>
<ul>
<li>The main confusion between the two papers is the use of <span class="math inline">\(\alpha\)</span>. The <span class="math inline">\(\alpha\)</span> used in DDIM is the same as <span class="math inline">\(\bar{\alpha}\)</span> of DDPM.</li>
<li>DDPM is a special case of DDIM.</li>
<li>They both have the same loss function, however, the reverse (generation) process is not the same.</li>
<li>This new generation process is what makes the inference process faster. Taking it from 1000 steps down to ~50.</li>
</ul>
<p>While the paper also discusses it’s approach in a stochastic differential equation sense, I will not go through this. I do not feel confident that I understood this aspect enough to explain. Nor do I think it’s necessary.</p>
<p>Keep in mind as we go through the following, that the aim is to find a way to sample from our data distribution <span class="math inline">\(q(x_0)\)</span>. We are not trying to find an analytical solution, nor an approximation to the actual distribution of <span class="math inline">\(x_0\)</span>. We do this by introducing some latent variables <span class="math inline">\(x_{1,…,T}\)</span>.</p>
</section>
<section id="the-forward-noising-process" class="level2">
<h2 class="anchored" data-anchor-id="the-forward-noising-process">The <del>forward</del> noising process</h2>
<p>Let us write down the joint distribution of x<span class="math inline">\(_0\)</span>, (the image space) with that of the latents <span class="math inline">\(x_{1,..,T}\)</span>.</p>
<p><strong>We construct</strong> our joint distribution such that <span class="math inline">\(x_{t-1}\)</span> is independent of all other latents given <span class="math inline">\(x_t, x_0\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
q_\sigma(x_{1:T}|x_0) &amp;= q_\sigma(x_{T-1}, x_{T-2}, ..., x_1|x_T, x_0)q_\sigma(x_T|x_0) \\
&amp;= q_\sigma(x_T|x_0) \prod_{t=2}^Tq_\sigma(x_{t-1}|x_t, x_0)
\end{align*}
\]</span></p>
<p>where,</p>
<p><span class="math display">\[
\begin{align*}
q_\sigma(x_T|x_0) &amp;= \mathcal{N}(\sqrt{\alpha_T}x_0, (1-\alpha_T)\mathbf{I}) \\
q_\sigma(x_{t-1}|x_t, x_0) &amp;= \mathcal{N}(\sqrt{\alpha_{t-1}}x_0 + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}x_0}{\sqrt{1-\alpha_t}}, \sigma^2 \mathbf{I})
\end{align*}
\]</span></p>
<p>just to reiterate, this is a design decision we make to construct the joint distribution this way. In general, <span class="math inline">\(q_\sigma(x_{T-1}, x_{T-2}, ..., x_1|x_T, x_0) \ne \prod_{t=2}^Tq_\sigma(x_{t-1}|x_t, x_0)\)</span>.</p>
<p>Although the paper refers to it as a forward process, the way we devise our model, <span class="math inline">\(q(x_t|x_{t-1}, x_0) \ne q(x_t|x_{t-1})\)</span>. Therefore not Markovian.</p>
<p>Once we have this it can be shown that <span class="math inline">\(q_\sigma(x_t|x_0) = \mathcal{N}(\sqrt{\alpha_t}x_0, (1-\alpha_t)\mathbf{I})\)</span> for all <span class="math inline">\(t\)</span>. The proof is shown by induction and is shown below. This result is important because it means that we can generate a sample <span class="math inline">\(x_t\)</span> without having to rely on <span class="math inline">\(x_{t-1}\)</span>. DDPM also has the same marginal distribution.</p>
<p>Given <span class="math inline">\(q_\sigma(x_t|x_0)\)</span> we can rewrite the distribution as,</p>
<p><span class="math display">\[
\begin{align*}
x_t &amp;= \sqrt{\alpha_t}x_0 + \sqrt{1-\alpha_t} \epsilon_t \\
\therefore \epsilon_t &amp;= \frac{x_t-\sqrt{\alpha_t}x_0}{\sqrt{1-\alpha_t}}
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(\epsilon_t \sim \mathcal{N}(0, \mathbf{I})\)</span>. This result can be substituted into q(x_{t-1}|x_t, x_0) to give,</p>
<p><span class="math display">\[
q_\sigma(x_{t-1}|x_t, x_0) = \mathcal{N}(\sqrt{\alpha_{t-1}}x_0 + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \epsilon_t, \sigma^2 \mathbf{I})
\]</span></p>
<p>Also worth noting that the marginals <span class="math inline">\(q(x_t|x_0)\)</span> remain the same even at the limit of <span class="math inline">\(\sigma \to 0\)</span>.</p>
<section id="proof-of-q_sigmax_tx_0" class="level3">
<h3 class="anchored" data-anchor-id="proof-of-q_sigmax_tx_0">Proof of <span class="math inline">\(q_\sigma(x_t|x_0)\)</span></h3>
<p>The following is a general Gaussian identity. Given the following distributions of <span class="math inline">\(x, y\)</span></p>
<p><span class="math display">\[
\begin{align*}
p(\mathbf{x}) &amp;= \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}, \boldsymbol{\Lambda}^{-1}) \\
p(\mathbf{y}|\mathbf{x}) &amp;= \mathcal{N}(\mathbf{y} | \mathbf{A}\mathbf{x} + \mathbf{b}, \mathbf{L}^{-1})
\end{align*}
\]</span></p>
<p>we have the marginal distribution of <span class="math inline">\(y\)</span> as,</p>
<p><span class="math display">\[
\begin{equation*}p(\mathbf{y}) = \mathcal{N}(\mathbf{y} | \mathbf{A}\boldsymbol{\mu} + \mathbf{b}, \mathbf{L}^{-1} + \mathbf{A}\mathbf{\Lambda}^{-1}\mathbf{A}^T)\end{equation*}
\]</span></p>
<p>The proof is by induction. Given <span class="math inline">\(q_\sigma(x_t|x_0)\)</span> and <span class="math inline">\(q_\sigma(x_{t-1}|x_t, x_0)\)</span> we will derive the form of <span class="math inline">\(q_\sigma(x_{t-1}|x_0)\)</span>.</p>
<p>If <span class="math inline">\(q_\sigma(x_t|x_0) = \mathcal{N}(\sqrt{\alpha_t}x_0, (1-\alpha_t)\mathbf{I})\)</span> and</p>
<p><span class="math display">\[
q_\sigma(x_{t-1}|x_t, x_0) = \mathcal{N}(\sqrt{\alpha_{t-1}}x_0 + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}x_0}{\sqrt{1-\alpha_t}}, \sigma^2 \mathbf{I})
\]</span></p>
<p>then,</p>
<p><span class="math display">\[
\begin{align*}
\mu &amp;\equiv \sqrt{\alpha_t}x_0 \\
\Lambda^{-1} &amp;\equiv (1-\alpha_t)\mathbf{I}\\
A &amp;\equiv \sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\\
b &amp;\equiv \sqrt{\alpha_{t-1}}x_0  - \sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\sqrt{\alpha_t}x_0\\
L^{-1} &amp;\equiv \sigma^2 \mathbf{I}
\end{align*}
\]</span></p>
<p>Therefore for <span class="math inline">\(q(x_{t-1}|x_0)\)</span> we have,</p>
<p><span class="math display">\[
\begin{align*}
A\mu + b &amp;= \cancel{\sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\sqrt{\alpha_t}x_0} + \sqrt{\alpha_{t-1}}x_0  - \cancel{\sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\sqrt{\alpha_t}x_0} \\
&amp;= \sqrt{\alpha_{t-1}}x_0 \\
\end{align*}
\]</span></p>
<p>and for the variance parameter, we have,</p>
<p><span class="math display">\[
\begin{align*}
\mathbf{L}^{-1} + \mathbf{A}\mathbf{\Lambda}^{-1}\mathbf{A}^T &amp;= \sigma^2 \mathbf{I} + \left(\sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\right)(1-\alpha_t)\mathbf{I}\left(\sqrt{\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_t}}\right)^T \\
&amp;= \sigma^2 \mathbf{I} + \left(\frac{1-\alpha_{t-1} - \sigma_t^2}{\cancel{1-\alpha_t}}\right)\cancel{(1-\alpha_t)}\mathbf{I} \\
&amp;= \cancel{\sigma^2 \mathbf{I}} + (1-\alpha_{t-1} - \cancel{\sigma_t^2})\mathbf{I} \\
&amp;= (1 - \alpha_{t-1})\mathbf{I}
\end{align*}
\]</span></p>
<p>which is the same form as <span class="math inline">\(q(x_t|x_0)\)</span> and concludes the proof via induction.</p>
</section>
</section>
<section id="reverse-generation-process" class="level2">
<h2 class="anchored" data-anchor-id="reverse-generation-process">Reverse (generation) process</h2>
<p>By the end of this section we will not have a closed form solution of what <span class="math inline">\(p(x_0)\)</span> is. Instead, what we end up is a generative process. Recall that <span class="math inline">\(x_{1:T}\)</span> are latent parameters but not <span class="math inline">\(x_0\)</span>.</p>
<p>Before getting into the process, let’s derive the loss that we are optimising.</p>
<p><span class="math display">\[
\begin{align*}
\log p(x_0) &amp;= \log \int p_\theta(x_{1:T},x_0) dx_{1:T} \\
&amp;= \log \int \frac{p_\theta(x_{1:T}, x_0) q_\sigma(x_{1:T} | x_0)}{q_\sigma(x_{1:T} | x_0)} dx_{1:T} \\
&amp;= \log \mathbb{E}_{q_\sigma(x_{1:T} | x_0)} \left[ \frac{p_\theta(x_{0:T})}{q_\sigma(x_{1:T} | x_0)} \right] \\
&amp;\geq \mathbb{E}_{q_\sigma(x_{1:T} | x_0)} \left[ \log \frac{p_\theta(x_{0:T})}{q_\sigma(x_{1:T} | x_0)} \right]
\end{align*}
\]</span></p>
<p>The last line being as a result of Jensen’s inequality. Obviously we do not know what <span class="math inline">\(p(x_0\)</span>) is for otherwise we would have solved this problem. But what we do have is a lower bound for any given <span class="math inline">\(x_0\)</span>. We have the definition of <span class="math inline">\(q_\sigma(x_{1:T}|x_0)\)</span> from above.</p>
<p>Before deriving the full lower bound, let’s recall that <span class="math inline">\(q_\sigma(x_t|x_0) = \mathcal{N}(\sqrt{\alpha_t}x_0, (1-\alpha_t)\mathbf{I})\)</span>. This can be re-written as</p>
<p><span class="math display">\[
\begin{align*}
x_t &amp;= \sqrt{\alpha_t}x_0 + \sqrt{1-\alpha_t}\epsilon \\
x_0 &amp;= \frac{x_t - \sqrt{1-\alpha_t}\epsilon}{\sqrt{\alpha_t}}
\end{align*}
\]</span></p>
<p>where <span class="math inline">\(\epsilon \sim \mathcal{N}(0, \mathbf{I})\)</span>.</p>
<p>However, during the generation process, we will estimate this noise using a neural network, <span class="math inline">\(\epsilon_\theta(.)\)</span>, given the noised image <span class="math inline">\(x_t\)</span>. Let’s call this estimate <span class="math inline">\(x_0\)</span>, <span class="math inline">\(f_\theta(x_t)\)</span>. Therefore,</p>
<p><span class="math display">\[
f_\theta^{(t)}(x_t) = \frac{x_t - \sqrt{1-\alpha_t}\epsilon_\theta^{(t)}(x_t)}{\sqrt{\alpha_t}}
\]</span></p>
<p>we can also rearrange the above, (which will come in handy soon).</p>
<p><span class="math display">\[
\epsilon_\theta^{(t)} = \frac{x_t - \sqrt{\alpha_t}f_\theta(x_t)}{\sqrt{1-\alpha_t}}
\]</span></p>
<p>We <strong>define</strong> <span class="math inline">\(p_\theta(x_{0:T}) = p_\theta(x_T)\prod_{t=1}^T p_\theta (x_{t-1}|x_t)\)</span></p>
<p>$$ <span class="math display">\[\begin{align*}
p^{(t)}(\mathbf{x}_{t-1}|\mathbf{x}_t) &amp;=
\begin{cases}
\mathcal{N}(f^{(1)}_\theta({x}_1), \sigma^2 \mathbf{I}) &amp; \text{if } t = 1 \\
q_\sigma({x}_{t-1}|{x}_t, f^{(t)}_\theta({x}_t)) &amp; \text{otherwise}
\end{cases}\\
p_\theta(x_T) &amp;= \mathcal{N}(0, \mathbf{I})
\end{align*}\]</span></p>
<p>$$</p>
<p>Note how we substitute <span class="math inline">\(f_\theta^{(t)}(x_t)\)</span> for all the <span class="math inline">\(x_0\)</span>’s in the above equation.</p>
</section>
<section id="lower-bound" class="level2">
<h2 class="anchored" data-anchor-id="lower-bound">Lower Bound</h2>
<p>Given this factorization, our negative (evidence) lower bound (ELBO), <span class="math inline">\(\mathcal{J}_\sigma\)</span> becomes,</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{J}_\sigma = \mathbb{E}_{x_{1:T|0} \sim q(x_{1:T|0})} [ &amp;\log q_\sigma(x_{T} | x_{0}) + \sum_{t=2}^{T} \log q_\sigma(x_{t-1} | x_{t}, x_{0}) - \sum_{t=1}^{T} \log p_\theta^{(t)} (x_{t-1} | x_{t}) - \log p_\theta(x_{T}) ]
\end{align*}
\]</span></p>
<p>the <span class="math inline">\(x_T\)</span> terms cancel each other out (as <span class="math inline">\(\alpha_T=0\)</span>), and instead of the expectation we take a Monte-Carlo estimate (single sample) of <span class="math inline">\(x_{1:T|0}\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
\mathcal{J}_\sigma &amp;= \mathbb{E}_{x_{1:T|0} \sim q(x_{1:T|0})} \left[ \sum_{t=2}^{T} \log q_\sigma(x_{t-1} | x_{t}, x_{0}) -  \sum_{t=1}^{T} \log p_\theta^{(t)} (x_{t-1} | x_{t}) \right] \\
&amp;= \mathbb{E}_{x_{1:T|0} \sim q(x_{1:T|0})} \left[ \sum_{t=2}^{T} \log \frac{q_\sigma(x_{t-1} | x_{t}, x_{0})}{p_\theta^{(t)} (x_{t-1} | x_{t})} - \log p^{(0)}_\theta (x_0|x_1)\right] \\
&amp;= \sum_{t=2}^{T} \int  q(x_{t-1}, x_t| x_0)\log \frac{q_\sigma(x_{t-1} | x_{t}, x_{0})}{p_\theta^{(t)} (x_{t-1} | x_{t})} dx_{t-1}dx_t -\int q(x_1|x_0)\log p^{(0)}_\theta (x_0|x_1)dx_1\\
&amp;= \sum_{t=2}^{T} \int q(x_t|x_0)\int q(x_{t-1}|x_t, x_0)\log \frac{q_\sigma(x_{t-1} | x_{t}, x_{0})}{p_\theta^{(t)} (x_{t-1} | x_{t})} dx_{t-1}dx_t -\mathbb{E}_{x_{1|0}} \log p^{(0)}_\theta (x_0|x_1) \\
&amp;= \sum_{t=2}^{T} E_{x_{t|0}}\left[ D_{KL}(q(x_{t-1}|x_t, x_0)|| p_\theta^{(t)} (x_{t-1} | x_{t}) )\right] -\mathbb{E}_{x_{1|0}} \log p^{(0)}_\theta (x_0|x_1)
\end{align*}
\]</span></p>
<p>where the last statement comes from the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Definition">definition of the KL divergence</a>. Given that <span class="math inline">\(q_\sigma(x_{t-1}|x_t, x_0) = \mathcal{N}(\sqrt{\alpha_{t-1}}x_0 + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}x_0}{\sqrt{1-\alpha_t}}, \sigma^2 \mathbf{I})\)</span> and <span class="math inline">\(p_\theta(x_{t-1}|x_0) = \mathcal{N}\left(\sqrt{\alpha_{t-1}}f_\theta(x_t) + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}f_\theta(x_t)}{\sqrt{1-\alpha_t}}, \sigma^2 \mathbf{I}\right)\)</span> and using the identity of <a href="https://stats.stackexchange.com/questions/60680/kl-divergence-between-two-multivariate-gaussians">KL divergence between two gaussians</a> where the variance is the same, we arrive at (by discarding constants),</p>
<p><span class="math display">\[
\begin{align*}
D_{KL}(q(x_{t-1}|x_t, x_0)|| p_\theta^{(t)} (x_{t-1} | x_{t}) ) =&amp; \frac{1}{2\sigma^2} (\mu_q-\mu_p)^2\\
=&amp;\frac{1}{2\sigma^2} (\\
&amp;\left(\sqrt{\alpha_{t-1}}x_0 + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}x_0}{\sqrt{1-\alpha_t}}\right) - \\
&amp;\left(\sqrt{\alpha_{t-1}}f_\theta(x_t) + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \frac{x_t - \sqrt{\alpha_t}f_\theta(x_t)}{\sqrt{1-\alpha_t}}\right)\\
&amp;)^2\\
=&amp;\frac{1}{2\sigma^2}\left(\sqrt{\alpha_{t-1}}(x_0-f_\theta(x_t))-\sqrt{\alpha_t\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_{t-1}}}(x_0-f_\theta(x_t))\right)^2\\
=&amp;\frac{1}{2\sigma^2}\left(\alpha_t-\sqrt{\alpha_t\frac{1-\alpha_{t-1} - \sigma_t^2}{1-\alpha_{t-1}}}\right)^2(x_0-f_\theta(x_t))^2\\
=&amp;\frac{1}{2\sigma^2}\gamma_t(x_0-f_\theta(x_t))^2
\end{align*}
\]</span></p>
<p>where I replaced the terms dependent on <span class="math inline">\(\alpha_*\)</span> as <span class="math inline">\(\gamma_t\)</span> as it can be a pre-computed constant. This is true even for the <span class="math inline">\(\mathbb{E}{x_{1|0}} \log p^{(0)}_\theta (x_0|x_1)\)</span> term.</p>
<p>Using the two identities, <span class="math inline">\(\epsilon_\theta^{(t)} = \frac{x_t - \sqrt{\alpha_t}f_\theta(x_t)}{\sqrt{1-\alpha_t}}\)</span> and <span class="math inline">\(f_\theta^{(t)}(x_t) = \frac{x_t - \sqrt{1-\alpha_t}\epsilon_\theta^{(t)}(x_t)}{\sqrt{\alpha_t}}\)</span> we can arrive at a similar conclusion with the KL divergence being</p>
<p><span class="math display">\[
\frac{1}{2\sigma^2}\gamma_t \frac{||\epsilon_t - \epsilon^{(t)}_\theta(x_t)||^2}{\alpha_td}
\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the dimensionality of the image <span class="math inline">\(x_*\)</span>.</p>
<p>This is the same objective as DDPM where we attempt to estimate the error with a neural network given the noised image <span class="math inline">\(x_t\)</span>.</p>
<p>While there is an expectation term around this loss, we take a Monte-Carlo sample instead of taking (the intractable) expectation.</p>
<p>While we can minimise this loss, we can think of the <span class="math inline">\(\frac{\gamma_t}{\alpha_t}\)</span> as an importance weighting of the loss at each time step. However, the neural network takes in two inputs, <span class="math inline">\(x_t\)</span> and the actual timestep <span class="math inline">\(t\)</span>. If we assume that each time-step has its own neural network, which it <strong>almost</strong> does due to it’s reliant on <span class="math inline">\(t\)</span>, we can instead simplify the simplified loss below instead (without the importance weighting).</p>
<p><span class="math display">\[
||\epsilon_t - \epsilon_\theta^{(t)}(x_t)||^2
\]</span></p>
<p>This is exactly what we do in DDPM.</p>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<p>The training is exactly the same of DDPM. i.e.&nbsp;We sample a noised image from <span class="math inline">\(t\sim{1,…,T}\)</span> and use a neural network to estimate the error.</p>
<p>Despite technically speaking, the loss is the expectation over <span class="math inline">\(x_t|x_0\)</span> and that we need to sum all the terms from <span class="math inline">\(1,…,T\)</span> we only sample one timestep <span class="math inline">\(t\)</span> and one noised image <span class="math inline">\(x_t\)</span>. This approximation does not affect the training since, 1. Sampling one noised image is still an unbiased estimate of the full expectation and 2. We are doing stochastic gradient descent over <strong>many</strong> iterations, therefore smoothing over any undesired estimates.</p>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>This is where the paths (between DDIM and DDPM) diverge. Let us rewrite <span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>.</p>
<p><span class="math display">\[
p_\theta(x_{t-1}|x_t) = \mathcal{N}(\sqrt{\alpha_{t-1}}f_\theta(x_t) + \sqrt{1-\alpha_{t-1} - \sigma_t^2} . \epsilon_\theta(x_t), \sigma^2 \mathbf{I})
\]</span></p>
<p>which we can rewrite as,</p>
<p>$$ x_{t-1} = <em>{ x_0 } + </em>{ x_t} + _{}</p>
<p>$$</p>
<p>This formulation is important since it states that at each denoising timestep we estimate <span class="math inline">\(x_0\)</span>. This means that we can skip a few of the time steps when denoising via the <span class="math inline">\(\sqrt{1 - \alpha_{t-1} - \sigma^2_t} \cdot \epsilon_\theta^{(t)}(x_t)\)</span> term. Also worth noting that even in the denoising step we add noise, but can be deterministic if we make <span class="math inline">\(\sigma_t = 0\)</span>.</p>
</section>
<section id="accelerated-sampling" class="level2">
<h2 class="anchored" data-anchor-id="accelerated-sampling">Accelerated Sampling</h2>
<p>To solidify this idea of skipping steps, they have introduced a slightly different noising and generative framework as shown below. Note that the noising process introduced before is not equivalent to this, and no amount of marginalising latents will lead to this formulation. This is again, by construction of the latents. <span class="math inline">\(\tau\)</span> are the skipped time steps and <span class="math inline">\(t \in \bar{\tau}\)</span> is it’s complement (everything else).</p>
<p><span class="math display">\[
\begin{align*}
&amp;q_{\sigma, \tau}(x_{1:T}|x_0) = q_{\sigma, \tau}(x_{\tau_S}|x_0)\prod_{i=1}^S q_{\sigma, \tau}(x_{\tau_{i-1}}|x_{\tau_i}, x_0) \prod_{t \in \bar{\tau}} q_{\sigma, \tau}(x_t|x_0) \\
&amp;q_{\sigma,\tau}(x_t | x_0) = \mathcal{N}(\sqrt{\alpha_t}x_0, (1 - \alpha_t)I) &amp;&amp;\forall t \in \bar{\tau} \cup  \{T\}\\
&amp;q_{\sigma,\tau}(x_{\tau_{i-1}} | x_{\tau_i}, x_0) = \mathcal{N}\left(\sqrt{\alpha_{\tau_{i-1}}}x_0 + \frac{\sqrt{1-\alpha_{\tau_{i-1}}} - \sigma^2_{\tau_i}}{\sqrt{1-\alpha_{\tau_i}}} \cdot x_{\tau_i}, \frac{\sqrt{\alpha_{\tau_i}}x_0}{\sqrt{1-\alpha_{\tau_i}}} - \sigma^2_{\tau_i}I\right) &amp;&amp;\forall i \in [S]
\end{align*}
\]</span></p>
<p>The corresponding generative process is as follows:</p>
<p><span class="math display">\[
\begin{align*}
&amp; p_{\theta}(x_{0:T}) := p_{\theta}(x_T) \underbrace{\prod_{i=1}^{S} p_{\theta}^{(\tau_i)} (x_{\tau_{i-1}} | x_{\tau_i})}_{\text{use to produce samples}} \times \underbrace{\prod_{t \in \bar{\tau}} p_{\theta}^{(t)} (x_0 | x_t)}_{\text{in variational objective}}\\
&amp; p_{\theta}^{(\tau_i)}(x_{\tau_{i-1}} | x_{\tau_i}) = q_{\sigma,\tau}(x_{\tau_{i-1}} | x_{\tau_i}, f_{\theta}^{(\tau_i)}(x_{\tau_{i-1}})) &amp;&amp;\text{if } i \in [S], i &gt; 1 \\
&amp; p_{\theta}^{(t)}(x_0 | x_t) = \mathcal{N}(f_{\theta}^{(t)}(x_t), \sigma_t^2 I) &amp;&amp;\text{otherwise}
\end{align*}
\]</span></p>
<p>While I will not derive the lower bound in this section, you can use almost the same equations in the lower bound section to derive the exact same loss above.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>To summarise all we have discussed above,</p>
<ul>
<li>We use the same loss function as DDPM, namely, the MSE of the estimated error function.</li>
<li>We use this equation to skip steps,</li>
</ul>
<p><span class="math display">\[
\begin{align*}
x_{\tau-1} = \sqrt{\alpha_{\tau-1}}  \underbrace{\left(\frac{x_\tau - \sqrt{1 - \alpha_\tau}\epsilon_\theta^{(\tau)}(x_\tau)}{\sqrt{\alpha_\tau}}\right)}_{\text{predicted } x_0 }  + \underbrace{\sqrt{1 - \alpha_{\tau-1} - \sigma^2_\tau} \cdot \epsilon_\theta^{(\tau)}(x_\tau)}_{\text{direction pointing to } x_\tau} + \underbrace{\sigma_\tau \epsilon_\tau}_{\text{random noise}}
\end{align*}
\]</span></p>
<ul>
<li>Setting <span class="math inline">\(\sigma_\tau \to 0\)</span> will allow you to sample determinstically starting from a given random state r<span class="math inline">\(x_T\)</span>.</li>
<li>Read the appendices.</li>
</ul>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>Kudos to <a href="https://www.linkedin.com/in/bpale/">Ben</a> senpai for encouraging me to stick with the DDIM paper.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/sachinruk\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2023, Sachinthaka Abeywardana</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sachinruk">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/sachinabeywardana/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/@deepschoolai">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>