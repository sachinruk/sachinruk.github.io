<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sachin Abeywardana">
<meta name="dcterms.date" content="2023-04-18">
<meta name="description" content="Code and Maths for Denoising Diffusion Probabilistic Models (DDPM)">

<title>deepschool.ai - Annotated DDPM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/favicon_logo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-37284264-2', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="deepschool.ai - Annotated DDPM">
<meta property="og:description" content="Code and Maths for Denoising Diffusion Probabilistic Models (DDPM)">
<meta property="og:image" content="https://sachinruk.github.io/images/ddpm_image.png">
<meta property="og:site-name" content="deepschool.ai">
<meta property="og:image:height" content="400">
<meta property="og:image:width" content="400">
<meta name="twitter:title" content="deepschool.ai - Annotated DDPM">
<meta name="twitter:description" content="Code and Maths for Denoising Diffusion Probabilistic Models (DDPM)">
<meta name="twitter:image" content="https://sachinruk.github.io/images/ddpm_image.png">
<meta name="twitter:image-height" content="400">
<meta name="twitter:image-width" content="400">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">deepschool.ai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../ML_consulting.html" rel="" target="">
 <span class="menu-text">ML Consulting</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../DL_Course.html" rel="" target="">
 <span class="menu-text">DL Course</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#diffusion-models" id="toc-diffusion-models" class="nav-link" data-scroll-target="#diffusion-models">Diffusion Models</a></li>
  <li><a href="#practical-considerations-of-solving-elbo" id="toc-practical-considerations-of-solving-elbo" class="nav-link" data-scroll-target="#practical-considerations-of-solving-elbo">Practical Considerations of Solving ELBO</a></li>
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a>
  <ul class="collapse">
  <li><a href="#noise-scheduler" id="toc-noise-scheduler" class="nav-link" data-scroll-target="#noise-scheduler">Noise Scheduler</a></li>
  </ul></li>
  <li><a href="#denoising-model" id="toc-denoising-model" class="nav-link" data-scroll-target="#denoising-model">Denoising Model</a>
  <ul class="collapse">
  <li><a href="#injecting-time-information-to-a-convolutional-network" id="toc-injecting-time-information-to-a-convolutional-network" class="nav-link" data-scroll-target="#injecting-time-information-to-a-convolutional-network">Injecting time Information to a Convolutional Network</a></li>
  <li><a href="#the-unet-architecture" id="toc-the-unet-architecture" class="nav-link" data-scroll-target="#the-unet-architecture">The UNet architecture</a></li>
  </ul></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference">Inference</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#acknowledgments-references" id="toc-acknowledgments-references" class="nav-link" data-scroll-target="#acknowledgments-references">Acknowledgments/ References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Annotated DDPM</h1>
  <div class="quarto-categories">
    <div class="quarto-category">deep-learning</div>
  </div>
  </div>

<div>
  <div class="description">
    Code and Maths for Denoising Diffusion Probabilistic Models (DDPM)
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sachin Abeywardana </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 18, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="../images/ddpm_image.png" class="img-fluid"></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>It took me many hours and weeks to understand DDPM (Denoising Diffusion Probabilistic Models). There were many intricacies in mapping my understanding from the math to code. This blog post is meant to cover both the maths side as well as coding. Hopefully, you will not need to venture outside this blog post. I will however assume familiarity with basic Bayesian methods, pytorch and some <strong>high level</strong> understanding of a UNet.</p>
<p>Before we get going Kudos to the <a href="https://course.fast.ai/Lessons/lesson19.html">fast.ai</a> explanation of DDPM.</p>
<p>I will also ask you to throw away presumptions about stable diffusion. DDPM while being one of the first papers that kicked off this area of Deep Learning does not take in a text input. However, hopefully you might see how to add such conditional information as we walk through this.</p>
<p>A working code example of this tutorial can be found on <a href="https://www.kaggle.com/code/sachin/ddpm-mnist">kaggle</a>.</p>
</section>
<section id="diffusion-models" class="level2">
<h2 class="anchored" data-anchor-id="diffusion-models">Diffusion Models</h2>
<p>The whole point of diffusion models is to model the data distribution <span class="math inline">\(p(x)\)</span>. This is done by transforming a Gaussian distribution <strong>iteratively</strong> through a neural network. This is different to GANs in that this transformation happens only once in GANs. Despite the multiple steps, the performance of diffusion models rates significantly higher.</p>
<p>In this section, we will step through the maths behind diffusion models. If this does not interest you, feel free to jump to the next section.</p>
<p>The rough idea behind diffusion models is the following integral: <span class="math display">\[
p(x) = \int p_\theta(x|x_1)p_\theta(x_1|x_2)...p_\theta(x_{T-1}|x_T)p(x_T)dx_1...dx_T
\]</span> The variables <span class="math inline">\(x_1,...,x_T\)</span> are latent (hidden) variables. In the final inference step, we throw away these variables.</p>
<p>In order to make this problem tractable we noise our input via a Gaussian distribution <span class="math inline">\(q(x_t|x_{t-1})=\mathcal{N}(\sqrt{\alpha_t}x_{t-1}, (1-\alpha_t)\mathbf{I})\)</span>. These alpha values are varied between 0 and 1. As alpha is close to zero <span class="math inline">\(q\)</span> is close to the standard normal while, at 1 it is close to being deterministically equal to the previous x timestep. The following diagram below shows how adding Gaussian noise moves you closer to a standard normal distribution on the right. <img src="https://i.imgur.com/6xu0ii6.png" class="img-fluid" alt="Image of non-gaussian distribution being transformed iteratively to Gaussian"></p>
<p><em>Source: <a href="https://cvpr2022-tutorial-diffusion-models.github.io/">Nvidia tutorial</a>.</em></p>
<p>So how do these q values come into play? Lucky for us, we can manipulate the above equation as following: <span class="math display">\[
\begin{align}
\log p(x) &amp;=  \log \int p_\theta(x|x_1)p_\theta(x_1|x_2)...p_\theta(x_{T-1}|x_T)dx_1...dx_T \\
\log p(x) &amp;= \log \int p_\theta(x|x_1)p_\theta(x_1|x_2)...p_\theta(x_{T-1}|x_T)\frac{q(x_1|x)q(x_2|x_1)...q(x_T|x_{T-1})}{q(x_1|x)q(x_2|x_1)...q(x_T|x_{T-1})}dx_1...dx_T \\
\log p(x) &amp;\ge E_{q(x_{1:T}|x_0)}\left[\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}\right]
\end{align}
\]</span> Where the last inequality came into play due to <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a>. Note in the second equation that <span class="math inline">\(p_\theta(x_1|x_2)\)</span> is in the reverse direction while <span class="math inline">\(q(x_2|x_1)\)</span> is in the forward direction. We solve the reverse process by maximising the lower bound with respect to <span class="math inline">\(\theta\)</span>. This lower bound is commonly known as the Evidence Lower Bound (ELBO).</p>
<p>In order for us to make the lower bound tractable we need a few more identities. <span class="math display">\[
q(x_t|x_{t-1}, x_0) = \frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}
\]</span> In order to get <span class="math inline">\(q(x_t|x_0)\)</span> given the equation <span class="math inline">\(q(x_t|x_{t-1})=\mathcal{N}(\sqrt{\alpha_t}x_{t-1}, (1-\alpha_t)\mathbf{I})\)</span>, we could iteratively integrate out <span class="math inline">\(x_{t-1}...x_0\)</span> which leads us to the following identity. <span class="math display">\[
q(x_t|x_0) = \mathcal{N}(\sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})\mathbf{I})
\]</span> where <span class="math inline">\(\bar{\alpha_t}\equiv \prod_{i=1}^t \alpha_i\)</span>. These values can be precomputed. Finally, we get this identity. <span class="math display">\[
\begin{align}
q(x_{t-1}|x_t, x_0) &amp;= \mathcal{N}(\mu_q(x_t, x_0), \sigma_q(t) \mathbf{I})\\
\mu_q(x_t, x_0) &amp;= \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})x_t + \sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)x_0}{(1-\bar{\alpha}_{t-1})} \\
\sigma_q(t) &amp;= \frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{(1-\bar{\alpha}_t)}
\end{align}
\]</span> It is worth noting that <span class="math inline">\(q(x_{t-1}|x_t, x_0)\)</span> is not tractable without the <span class="math inline">\(x_0\)</span>. If it were, computing <span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span> would have been trivial.</p>
<p>Returning back to the lower bound, we can now rewrite it as, <span class="math display">\[
\begin{align}
\log p(x) \ge &amp; E_{q(x_{1:T}|x_0)}\left[\log\frac{p(x_T)p_\theta(x_0|x_1)}{q(x_1|x_0)} + \log \prod_{t=2}^T \frac{p_\theta(x_{t-1}|x_0)}{\frac{q(x_{t-1}|x_t, x_0)q(x_t|x_0)}{q(x_{t-1}|x_0)}}\right]\\
\ge &amp; E_{q(x_{1}|x_0)}(\log p_\theta(x_0|x_1)) - \mathcal{D}_{KL}(q(x_T|x_0)|| p(x_T)) - \sum_{t=2}^TE_{q(x_{t}|x_0)}\left(\mathcal{D}_{KL}(q(x_{t-1}|x_t, x_0)||p_\theta(x_{t-1}|x_t))\right)
\end{align}
\]</span> The middle term of the above has no relation to <span class="math inline">\(\theta\)</span> and therefore can be ignored.</p>
<p>I understand that I might have skipped quite a few steps in deriving the above. If you wish to see the full expansion you can see that in <a href="https://arxiv.org/pdf/2208.11970.pdf">page 9 of this paper</a>.</p>
</section>
<section id="practical-considerations-of-solving-elbo" class="level2">
<h2 class="anchored" data-anchor-id="practical-considerations-of-solving-elbo">Practical Considerations of Solving ELBO</h2>
<p>Firstly, we set <span class="math inline">\(p_\theta\)</span> to be Gaussian so that <span class="math display">\[
p_\theta(x_{t-1}|x_t) = \mathcal{N}(\mu_\theta(x_t, t), \sigma_q(t)\mathbf{I})
\]</span> where <span class="math inline">\(\mu_\theta\)</span> is a neural network that transforms <span class="math inline">\(x_t\)</span> and we set the variance to be equal to that of <span class="math inline">\(q(x_{t-1}|x_t, x_0)\)</span>. Note that even if <span class="math inline">\(x_t\)</span> was Gaussian <span class="math inline">\(p_\theta(x_{t-1})\)</span> is not Gaussian. This is because <span class="math inline">\(\mu_\theta\)</span> transforms the distribution.</p>
<p>In the ELBO term above, for the expectation terms we simply take a monte-carlo estimate (one sample of the distribution) since the expectations are intractable. This does not detract from estimating <span class="math inline">\(p_\theta\)</span> since we are doing <em>stochastic</em> gradient descent, and also due to the fact that these single sample estimates are unbiased.</p>
<p>For the second term, <span class="math inline">\(q(x_T|x_0)\)</span> is far enough from the original distribution that it is safe to assume that it is a standard normal distribution, and <span class="math inline">\(p(x_T)\)</span> is a standard normal by definition. Regardless, this term does not depend on <span class="math inline">\(\theta\)</span> and therefore can be discarded.</p>
<p>The final term is the most important term and works out to optimising <span class="math inline">\(\theta\)</span> over the following: <span class="math display">\[
\argmin_\theta\frac{1}{2\sigma_q^2(t)}||\mu_q(x_t, x_0) - \mu_\theta ||_2^2
\]</span> While we could use this loss to optimise, we will refactor further to achieve a similar yet emperically more powerful term. We can reuse <span class="math inline">\(q(x_t|x_0)\)</span> to state that, <span class="math display">\[
x_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}
\]</span> Substituting this into <span class="math inline">\(\mu_q\)</span> we arrive at <span class="math display">\[
\mu_q(x_t, x_0)=\frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon_0
\]</span> Therefore if we use <span class="math display">\[
\mu_\theta(x_t, x_0)=\frac{1}{\sqrt{\alpha_t}}x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon_\theta(x_t, x_0)
\]</span> we arrive at our final loss function: <span class="math display">\[
\mathcal{L} = \argmin_\theta\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\epsilon_0 - \epsilon_\theta(x_t, t) ||_2^2
\]</span> It has been emperically found that we can drop <span class="math inline">\(\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}\)</span> term. This term can be thought of as a weighting term over the time steps which has been deemed unnecessary. Finally, do note that the loss is with respect to <span class="math inline">\(\epsilon_0\)</span>, and not simply the scaled noise which may be much smaller in magnitude.</p>
<p>Finally, since we have the ability to sample <span class="math inline">\(q(x_t|x_0)\)</span> directly without having to sample intermediate steps, we can take just a single sample per <span class="math inline">\(x_0\)</span> without summing the KL divergence over all time-steps as suggested.</p>
<p>The final algorithm for DDPM can be summarised as follows. Note how for inference we have no option but to sample over all time steps. <img src="https://i.imgur.com/dhJ4x7j.png" class="img-fluid" alt="DDPM training algorithm"> <em>Source: Page 4 <a href="https://arxiv.org/pdf/2006.11239.pdf">DDPM paper</a></em></p>
</section>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<p>There are four aspects to (as far as I know) all diffusion models. These are: 1. Noise Scheduler 2. Noise Estimation Model 3. Training Process 4. Inference Process We will go into depth into each component.</p>
<section id="noise-scheduler" class="level3">
<h3 class="anchored" data-anchor-id="noise-scheduler">Noise Scheduler</h3>
<p>The noise scheduler enables us to add noise to the image. While we could have a constant level of noise, the model learns better when it is varied. Below, we vary it linearly, however, another common scheduler is to use a cosine scheduler which performs even better.</p>
<p>Note how <span class="math inline">\(\bar{\alpha}_t\)</span> is precomputed as <code>alphas_cumprod</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DDPMScheduler:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, beta_start, beta_end, num_train_timesteps):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># for the forward process q(x_t|x_0)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.timesteps <span class="op">=</span> torch.arange(num_train_timesteps)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta_start <span class="op">=</span> beta_start</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta_end <span class="op">=</span> beta_end</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_train_steps <span class="op">=</span> num_train_timesteps</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> torch.linspace(<span class="va">self</span>.beta_start, <span class="va">self</span>.beta_end, <span class="va">self</span>.num_train_steps)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alphas <span class="op">=</span> <span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.beta</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alphas_cumprod <span class="op">=</span> torch.cumprod(<span class="va">self</span>.alphas, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># for the reverse process q(x_{t-1}|x_t,x_0)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigmas <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.alphas[<span class="dv">1</span>:]) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>]) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod[<span class="dv">1</span>:])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigmas <span class="op">=</span> <span class="va">self</span>.sigmas.sqrt()</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_noise(<span class="va">self</span>, x0, noise, t):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        alphas_cumprod_t <span class="op">=</span> <span class="va">self</span>.alphas_cumprod.to(x0.device)[t].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> alphas_cumprod_t.sqrt() <span class="op">*</span> x0 <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> alphas_cumprod_t).sqrt() <span class="op">*</span> noise</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="denoising-model" class="level2">
<h2 class="anchored" data-anchor-id="denoising-model">Denoising Model</h2>
<p>When speaking of the denoising model, the term UNet gets thrown around frequently. However, it is worth noting that there are only two requirements of this model, 1. The model takes in the inputs, <span class="math inline">\(x_t\)</span> (the noised image), as well as the time step <span class="math inline">\(t\)</span>. 2. The size of the output has to be the same as <span class="math inline">\(x_t\)</span>. It is because of the latter requirement that UNets are commonly used. However, as long as you can project the final dimension size back to the same as the input dimension, there is no definite requirement for UNets alone.</p>
<p>In the following we will focus on 1. How to add time information to a ConvNet via <code>ResNetWithTimeEmbed</code>. 2. The UNet architecture. Especially focusing on hooks.</p>
<section id="injecting-time-information-to-a-convolutional-network" class="level3">
<h3 class="anchored" data-anchor-id="injecting-time-information-to-a-convolutional-network">Injecting time Information to a Convolutional Network</h3>
<p>As we denoise our images (or rather estimate the original noise to be more specific), we require an input of the time-step. This allows the network to know the scale of the noise, while also knowing how far it is from the original image. The fact that we vary noise via the Noise Scheduler makes this information even more valuable.</p>
<p>In the following I have used a linear layer to project the time step to a higher dimension. The logic being that there ought to be a relationship between time step <code>t</code> and <code>t+1</code>. However, it is also common to simply use an embedding layer here. The dimensionality is the same as the final channel in the last convolutional layer.</p>
<p>Finally, we repeat this over the width and height dimensions before adding onto <code>x</code>. <code>x</code> in this case could be the original image or one of the intermediate noised images.</p>
<p>For brevity, we will skip the explanation of <code>ResNetBlock</code> in the following as it could simply be a convolutional network.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNetWithTimeEmbed(nn.Module):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels, stride<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet1 <span class="op">=</span> ResNetBlock(in_channels, out_channels)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet2 <span class="op">=</span> ResNetBlock(out_channels, out_channels, stride)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_embedding <span class="op">=</span> nn.Linear(<span class="dv">1</span>, out_channels)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.FloatTensor, t: torch.LongTensor) <span class="op">-&gt;</span> torch.FloatTensor:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.resnet2(<span class="va">self</span>.resnet1(x))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        time_embed <span class="op">=</span> <span class="va">self</span>.time_embedding(t)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> time_embed[:, :, <span class="va">None</span>, <span class="va">None</span>].repeat(<span class="dv">1</span>, <span class="dv">1</span>, x.shape[<span class="op">-</span><span class="dv">2</span>], x.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> emb</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-unet-architecture" class="level3">
<h3 class="anchored" data-anchor-id="the-unet-architecture">The UNet architecture</h3>
<p>UNet contains a downscaling architecture followed by upscaling. Both architectures contain <code>ResNetWithTimeEmbed</code> components as discussed above.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Down(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers: List[<span class="bu">int</span>]):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_layers <span class="op">=</span> nn.ModuleList([ResNetWithTimeEmbed(dim_in, dim_out) <span class="cf">for</span> dim_in, dim_out <span class="kw">in</span> <span class="bu">zip</span>(layers[:<span class="op">-</span><span class="dv">1</span>], layers[<span class="dv">1</span>:])])</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bns <span class="op">=</span> nn.ModuleList([nn.BatchNorm2d(feature_len) <span class="cf">for</span> feature_len <span class="kw">in</span> layers[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer, batch_norm <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.conv_layers[:<span class="op">-</span><span class="dv">1</span>], <span class="va">self</span>.bns):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.down(batch_norm(F.gelu(layer(x, t))))</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.down(<span class="va">self</span>.conv_layers[<span class="op">-</span><span class="dv">1</span>](x, t))</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Up(nn.Module):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers: List[<span class="bu">int</span>]):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up <span class="op">=</span> nn.Upsample(scale_factor<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">"bilinear"</span>, align_corners<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_layers <span class="op">=</span> nn.ModuleList([ResNetWithTimeEmbed(dim_in, dim_out) <span class="cf">for</span> dim_in, dim_out <span class="kw">in</span> <span class="bu">zip</span>(layers[:<span class="op">-</span><span class="dv">1</span>], layers[<span class="dv">1</span>:])])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bns <span class="op">=</span> nn.ModuleList([nn.BatchNorm2d(feature_len) <span class="cf">for</span> feature_len <span class="kw">in</span> layers[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer, batch_norm <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.conv_layers[:<span class="op">-</span><span class="dv">1</span>], <span class="va">self</span>.bns):</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> F.gelu(batch_norm(layer(<span class="va">self</span>.up(x), t)))</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.conv_layers[<span class="op">-</span><span class="dv">1</span>](<span class="va">self</span>.up(x), t)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UNet(nn.Module):</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers: List[<span class="bu">int</span>]):</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up <span class="op">=</span> Up(layers[::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down <span class="op">=</span> Down(layers)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down_outputs <span class="op">=</span> []</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up.up.register_forward_hook(<span class="kw">lambda</span> module, <span class="bu">input</span>, output: output <span class="op">+</span> <span class="va">self</span>.down_outputs.pop(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> module <span class="kw">in</span> <span class="va">self</span>.down.conv_layers.children():</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>            module.register_forward_hook(<span class="kw">lambda</span> module, <span class="bu">input</span>, output: <span class="va">self</span>.down_outputs.append(output))</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.up(<span class="va">self</span>.down(x, t), t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>Down</code> uses <code>nn.MaxPool2d(2)</code> to get the maximum value in a 2x2 region to downscale while, <code>Up</code> uses <code>nn.Upsample</code> to expand the width and height by a factor of 2. The latter takes a linear interpolation method to quadruple the number of pixels. Both methods are preceded by a <code>ResNetWithTimeEmbed</code> which does not change the height or width, but does increase/ decrese the number of channels.</p>
<p>While it was possible to simply do <code>self.up(self.down(x, t), t)</code>, it made a significant difference to the loss function (which was previously struggling) to include cross-connections. Cross connections are depicted by the grey horizontal arrows below. The loss runs where it was &gt;0.6 were all when the model did not have those cross-connections.</p>
<p float="left">
<img src="https://i.imgur.com/gLJQury.png" alt="Diagram of a UNet" width="45%"> <img src="https://i.imgur.com/jFs0OPg.png" alt="W+B Loss chart over many runs" width="45%">
</p>
<p>In order to get these cross connections we use this nifty feature called <code>forward_hooks</code>. Any submodule within a model can <code>register_forward_hook</code>s. It has three inputs into it, 1. The module itself, 2. The current input(s) into the model 3. The output(s).</p>
<p>Firstly, we save the outputs of the <code>Down</code> modules into the buffer named <code>self.down_outputs</code>. Note how we only do this to the <code>conv_layers</code> of the <code>Down</code> class and does not include the down-sampling maxpool operation.</p>
<p>The next step is to add these values in the buffer to the layers of the <code>Up</code> module. This is done again by the forward hook using this function: <code>lambda module, input, output: output + self.down_outputs.pop(-1)</code>. This function pops out the last layer of the buffer, but more importantly, it modifies the output. Note how this hook is registered to the <code>self.up.up</code> module. Despite not having submodules like the above <code>self.conv_layers</code>, this hook fires every time <code>self.up.up</code> is called.</p>
<p>It is also worth noting that there was a bit of trial and error for me to figure out where to place the hooks so that the shapes match up. I also had to resize the inputs to be of size 32x32 so that the down/up-scaling did not affect the width and height required for this addition operation.</p>
</section>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<p>The training loop is as shown below. The most important thing to note here is how the loss is estimated. Firstly, note that we only take a batch size of time-steps instead of the full possible 1000 steps. This is depite the original loss function requiring you to sum over all timesteps. However, we can think of this is as a noisy estimate which is scaled down by a factor of <span class="math inline">\(\frac{bs}{T}\)</span>. Furthermore, the KL-divergence term is also over the expectation under <span class="math inline">\(q(x_t|x_0)\)</span>. The expectation again is also ignored and only a single sample of <span class="math inline">\(x_t\)</span> is taken for each <span class="math inline">\(x_0\)</span>. This is called taking a monte-carlo estimate in literature, and gives us a noisy estimate of the expectation.</p>
<p>Despite these approximations, our model manages to learn a good denoiser as shown in the results section. This is due to the fact that we are optimising over many iterations to optimise over <span class="math inline">\(\theta\)</span>. The noisy estimates ends up being of little to no consequence.</p>
<p>I do also wish to point out that I used gradient clipping. I am fairly convinced that everyone should use this no matter what problem you are tackling using Deep Learning. It made my training significantly smoother.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(EPOCHS)):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (x, _) <span class="kw">in</span> <span class="bu">enumerate</span>(train_dl):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(DEVICE)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn(x.shape).to(DEVICE)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        timesteps <span class="op">=</span> torch.randint(<span class="dv">0</span>, NUM_DIFFUSION_STEPS, (<span class="bu">len</span>(x),)).<span class="bu">long</span>().to(DEVICE)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        noised_images <span class="op">=</span> noise_scheduler.add_noise(x, noise, timesteps)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> model(noised_images, timesteps[:, <span class="va">None</span>] <span class="op">/</span> NUM_DIFFUSION_STEPS)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.mse_loss(noise_pred, noise, reduction<span class="op">=</span><span class="st">"none"</span>).mean()        </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> LOG_FREQUENCY <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            loss_detached <span class="op">=</span> loss.detach().item()</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            wandb.log({<span class="st">"loss"</span>: loss_detached})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>Unfortunately, inference is costly under DDPM taking a 1000 iterations of the model denoising to reach the final state. The number of steps required to denoise are continuously becoming less and less with some of the latest papers.</p>
<p>In this case we repeatedly use the distribution <span class="math inline">\(p_\theta(x_{t-1}|x_t) = \mathcal{N}(\mu_\theta(x_t, t), \sigma_q(t)\mathbf{I})\)</span> until we get to <span class="math inline">\(x_0\)</span>. Note also how we actually add more noise during the denoising process. <span class="math inline">\(\sigma_t\)</span> does however get smaller the closer we are to <span class="math inline">\(x_0\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_denoised_images_ddpm(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    model: nn.Module,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    diffusion_steps: <span class="bu">int</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    x_t: torch.FloatTensor,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    noise_scheduler</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> List[torch.FloatTensor]:        </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(diffusion_steps <span class="op">-</span> <span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>            time <span class="op">=</span> torch.FloatTensor([t] <span class="op">*</span> <span class="bu">len</span>(x_t))[:, <span class="va">None</span>] <span class="op">/</span> diffusion_steps</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>            noise_pred <span class="op">=</span> model(x_t.to(DEVICE), time.to(DEVICE))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>            alpha_bar_t <span class="op">=</span> noise_scheduler.alphas_cumprod[t]</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>            alpha_t <span class="op">=</span> noise_scheduler.alphas[t]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>            sigma_t <span class="op">=</span> noise_scheduler.sigmas[t <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>            mu_t <span class="op">=</span> (x_t.to(DEVICE) <span class="op">-</span> ((<span class="dv">1</span> <span class="op">-</span> alpha_t) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> alpha_bar_t).sqrt()) <span class="op">*</span> noise_pred) <span class="op">/</span> alpha_t.sqrt()</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            x_t <span class="op">=</span> mu_t <span class="op">+</span> torch.randn_like(mu_t) <span class="op">*</span> sigma_t</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The following shows results of where some of the intermediate steps were also saved. <img src="https://i.imgur.com/qUXpV2d.png" class="img-fluid" alt="Fashion MNIST DDPM Results 1"></p>
</section>
<section id="acknowledgments-references" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments-references">Acknowledgments/ References</h2>
<p>If this blog is still leaving you with questions, I would personally recommend the following 3 resources (in order of awesomeness):</p>
<ol type="1">
<li><a href="https://course.fast.ai/Lessons/lesson19.html">Fast.ai course page</a></li>
<li>For a deep dive into the maths read <a href="https://arxiv.org/pdf/2208.11970.pdf">this paper</a>.</li>
<li><a href="https://www.youtube.com/watch?v=cS6JQpEY9cs&amp;ab_channel=ArashVahdat">YouTube tutorial</a> by Nvidia.</li>
<li>The actual <a href="https://arxiv.org/pdf/2006.11239.pdf">DDPM paper</a>.</li>
</ol>
<p>I also want to thank <a href="https://www.linkedin.com/in/bpale/">Ben Alexander</a> for helping me untie some of the ugly knots in my understanding of Diffusion Models.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, Sachinthaka Abeywardana</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sachinruk">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://https://www.linkedin.com/in/sachinabeywardana/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/@deepschoolai">
      <i class="bi bi-youtube" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>