{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /2021/08/28/Weighted-Cross-Entropy-Loss\n",
    "date: '2021-08-28'\n",
    "description: An alternative approach to Focal Loss\n",
    "output-file: 2021-08-28-weighted-cross-entropy-loss.html\n",
    "title: An Intuitive Loss for Imbalanced Classification\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/segmentation.jpg)\n",
    "## Introduction\n",
    "Getting an intuitive loss function when there are large class imbalances remains a hot topic. Some of the common techniques involve, re-weighting classes and lately [focal loss](https://paperswithcode.com/method/focal-loss). [This paper](https://arxiv.org/pdf/2001.00570.pdf) is a good overview of re-weighting methods. The following idea is not mine and is something I saw on kaggle (but could not find again ðŸ˜¢).\n",
    "\n",
    "The basic crux of the following loss is simple. We will use the cross entropy loss as usual, however we will have a dynamic weighting scheme. We start off as having all classes being equally important. However, as training evolves for each batch we calculate the false negative rate. That is for a given class, what proportion of that class was mis-labelled. During training the model will get better at some classes (especially the over represented), and have a small false negative rate. We use an exponentially smoothed version of this false negative rate as the importance of that class during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self, num_classes: int, alpha: float=1e-2) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        self.register_buffer(\"importance\", torch.ones(num_classes).float())\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def compute_false_negative_rate(self, y, pred_class) -> None:\n",
    "        wrong_preds = y != pred_class\n",
    "        wrong_categories, false_negatives = y[wrong_preds].unique(return_counts=True)\n",
    "        categories, actual_counts = y.unique(return_counts=True)\n",
    "        \n",
    "        false_negative_rate = torch.zeros_like(categories).float()\n",
    "        \n",
    "        idx = (categories[:, None] == wrong_categories[None, :]).nonzero(as_tuple=True)[0]\n",
    "        false_negative_rate[idx] = false_negatives / actual_counts[idx]\n",
    "        \n",
    "        self.importance[categories] = self.alpha * false_negative_rate + (1 - self.alpha) * self.importance[categories]\n",
    "        \n",
    "    def forward(self, logits: torch.FloatTensor, y: torch.LongTensor) -> torch.FloatTensor:\n",
    "        pred_class = logits.argmax(dim=1)\n",
    "        self.compute_false_negative_rate(y, pred_class)\n",
    "        \n",
    "        return (self.loss_fn(logits, y) * self.importance[y]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The top image below is with normal cross entropy loss without any re-weighting, and the bottom image is with re-weighting.\n",
    "![poor result with ce loss](../images/segmentation_ce_loss.png)\n",
    "\n",
    "![good result with weighted loss](../images/segmentation_weighted_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shameless Self Promotion\n",
    "If you enjoyed the tutorial buy me a coffee, or better yet [buy my course](https://www.udemy.com/course/machine-learning-and-data-science-2021/?referralCode=E79228C7436D74315787) (usually 90% off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
